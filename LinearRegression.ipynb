{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg3M_EsX-GvV"
      },
      "outputs": [],
      "source": [
        "class MyLineReg():\n",
        "  def __init__(self, n_iter = 100, learning_rate = 0.1, weights = None, metric = None, reg = None, l1_coef = 0, l2_coef = 0, sgd_sample = None, random_state = 42, **kwargs):\n",
        "    self.n_iter = n_iter\n",
        "    self.learning_rate = learning_rate\n",
        "    self.params = kwargs\n",
        "    self.weights = weights\n",
        "    self.metric = metric\n",
        "    self.reg = reg\n",
        "    self.l1_coef= l1_coef\n",
        "    self.l2_coef = l2_coef\n",
        "    self.sgd_sample = sgd_sample\n",
        "    self.random_state = random_state\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    base_str = f'MyLineReg class: n_iter={self.n_iter}, learning_rate={self.learning_rate}'\n",
        "    if self.params:\n",
        "      param_str = ', '.join([f\"{key}={value}\" for key, value in self.params.items()])\n",
        "      return f\"{base_str}, {param_str}\"\n",
        "    return base_str\n",
        "\n",
        "\n",
        "  def calculate_metric(self, y_true, y_pred):\n",
        "    if self.metric == 'mae':\n",
        "      return np.mean(np.abs(y_true - y_pred))\n",
        "    elif self.metric == 'rmse':\n",
        "      return np.sqrt(np.mean(np.square(y_true - y_pred)))\n",
        "    elif self.metric == 'r2':\n",
        "      return 1 - np.sum(np.square(y_true - y_pred)) / np.sum(np.square(y_true - np.mean(y_true)))\n",
        "    elif self.metric == 'mape':\n",
        "      return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    elif self.metric == 'mse':\n",
        "      return np.mean(np.square(y_true - y_pred))\n",
        "    else:\n",
        "      return None\n",
        "\n",
        "\n",
        "  def fit(self, X, y, verbose = False):\n",
        "    random.seed(self.random_state)\n",
        "    X.insert(0, 'Ones', 1)\n",
        "    self.weights = np.ones(X.shape[1])\n",
        "\n",
        "    for i in range(self.n_iter):\n",
        "      if self.sgd_sample:\n",
        "        if type(self.sgd_sample) == int:\n",
        "          sample_rows_idx = random.sample(range(X.shape[0]), self.sgd_sample)\n",
        "        elif type(self.sgd_sample) == float:\n",
        "          sample_rows_idx = random.sample(range(X.shape[0]), int(self.sgd_sample * X.shape[0]))\n",
        "\n",
        "        y_pred = X.dot(self.weights)\n",
        "        X_mini_batch = X.iloc[sample_rows_idx]\n",
        "        y_mini_batch = y.iloc[sample_rows_idx]\n",
        "        y_pred_mini = X_mini_batch.dot(self.weights)\n",
        "        error_mini = y_pred_mini - y_mini_batch\n",
        "        gradient_mini = 2 / len(y_mini_batch) * error_mini.dot(X_mini_batch)\n",
        "        MSE = np.mean(np.square(y_pred - y))\n",
        "\n",
        "        if self.reg == 'l1':\n",
        "          MSE = MSE + self.l1_coef * np.sum(np.abs(self.weights))\n",
        "          gradient_mini = gradient_mini + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "          MSE = MSE + self.l2_coef * np.sum(np.square(self.weights))\n",
        "          gradient_mini = gradient_mini + self.l2_coef * 2 * self.weights\n",
        "        elif self.reg == 'elasticnet':\n",
        "          MSE = MSE + self.l1_coef * np.sum(np.abs(self.weights)) + self.l2_coef * np.sum(np.square(self.weights))\n",
        "          gradient_mini = gradient_mini + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * self.weights\n",
        "\n",
        "        if isinstance(self.learning_rate, (int, float)):\n",
        "          self.weights -= self.learning_rate * gradient_mini\n",
        "        else:\n",
        "          self.weights -= self.learning_rate(i + 1) * gradient_mini\n",
        "\n",
        "      else:\n",
        "        y_pred = X.dot(self.weights)\n",
        "        error = y_pred - y\n",
        "        MSE = np.mean(np.square(error))\n",
        "        gradient = 2 / len(y) * error.dot(X)\n",
        "\n",
        "        if self.reg == 'l1':\n",
        "          MSE = MSE + self.l1_coef * np.sum(np.abs(self.weights))\n",
        "          gradient = gradient + self.l1_coef * np.sign(self.weights)\n",
        "        elif self.reg == 'l2':\n",
        "          MSE = MSE + self.l2_coef * np.sum(np.square(self.weights))\n",
        "          gradient = gradient + self.l2_coef * 2 * self.weights\n",
        "        elif self.reg == 'elasticnet':\n",
        "          MSE = MSE + self.l1_coef * np.sum(np.abs(self.weights)) + self.l2_coef * np.sum(np.square(self.weights))\n",
        "          gradient = gradient + self.l1_coef * np.sign(self.weights) + self.l2_coef * 2 * self.weights\n",
        "\n",
        "        if isinstance(self.learning_rate, (int, float)):\n",
        "          self.weights -= self.learning_rate * gradient\n",
        "        else:\n",
        "          self.weights -= self.learning_rate(i + 1) * gradient\n",
        "\n",
        "        self.metric_value = self.calculate_metric(y, y_pred)\n",
        "\n",
        "      if verbose and (i + 1) % verbose == 0:\n",
        "        print(f'{i + 1} / loss : {MSE} / {self.metric} : {self.metric_value} / learning_rate : {self.learning_rate}')\n",
        "\n",
        "\n",
        "  def get_coef(self):\n",
        "    return np.array(self.weights)[1:]\n",
        "\n",
        "  def predict(self, X):\n",
        "    X.insert(0, 'Ones', 1)\n",
        "    y_pred = X.dot(self.weights)\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "  def get_best_score(self):\n",
        "    return self.metric_value\n"
      ]
    }
  ]
}